volumes:
  n8n_storage:
  postgres_storage:
  # ollama_storage:
  # qdrant_storage:
  # redis_storage:
  es_data:
  kafka-data:
  # prometheus_data:
  # grafana_data:

networks:
  demo:

x-n8n: &service-n8n
  image: n8nio/n8n:latest
  networks: ['demo']
  environment:
    - DB_TYPE=postgresdb
    - DB_POSTGRESDB_HOST=postgres
    - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_SECURE_COOKIE=false
    - N8N_PERSONALIZATION_ENABLED=false
    - N8N_ENCRYPTION_KEY
    - N8N_USER_MANAGEMENT_JWT_SECRET
    - OLLAMA_HOST=${OLLAMA_HOST:-ollama:11434}
  env_file:
    - path: .env
      required: true

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  networks: ['demo']
  restart: unless-stopped
  ports:
    - 11434:11434
  volumes:
    - ollama_storage:/root/.ollama

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  networks: ['demo']
  container_name: ollama-pull-llama
  volumes:
    - ollama_storage:/root/.ollama
  entrypoint: /bin/sh
  environment:
    - OLLAMA_HOST=ollama:11434
  command:
    - "-c"
    - "sleep 3; ollama pull llama3.2"

services:
       
  postgres:
    image: postgres:16-alpine
    hostname: postgres
    networks: ['demo']
    restart: unless-stopped
    environment:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - POSTGRES_DB
    volumes:
      - postgres_storage:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 10

  n8n-import:
    <<: *service-n8n
    hostname: n8n-import
    container_name: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/demo-data/credentials && n8n import:workflow --separate --input=/demo-data/workflows"
    volumes:
      - ./n8n/demo-data:/demo-data
    depends_on:
      postgres:
        condition: service_healthy

  n8n:
    <<: *service-n8n
    hostname: n8n
    container_name: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    volumes:
      - n8n_storage:/home/node/.n8n
      - ./n8n/demo-data:/demo-data
      - ./shared:/data/shared
    depends_on:
      postgres:
        condition: service_healthy
      n8n-import:
        condition: service_completed_successfully


  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.15.0   # Match Elasticsearch version
  #   container_name: kibana
  #   ports:
  #     - "5601:5601"
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - demo
      
  # filebeat:
  #   image: docker.elastic.co/beats/filebeat:8.15.3
  #   container_name: filebeat
  #   user: root   # needed so filebeat can read mounted config
  #   networks: ['demo']
  #   volumes:
  #     - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
  #   command: ["--strict.perms=false", "-e"]
  #   depends_on:
  #     - kafka
  #     - elasticsearch
 
 
  # qdrant:
  #   image: qdrant/qdrant
  #   hostname: qdrant
  #   container_name: qdrant
  #   networks: ['demo']
  #   restart: unless-stopped
  #   ports:
  #     - 6333:6333
  #   volumes:
  #     - qdrant_storage:/qdrant/storage

  # redis:
  #   image: redis:7-alpine
  #   container_name: redis
  #   hostname: redis
  #   networks: ['demo']
  #   restart: unless-stopped
  #   volumes:
  #     - redis_storage:/data

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.3
    container_name: elasticsearch
    networks: ['demo']
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_PASSWORD=changeme
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:changeme http://localhost:9200 >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  
  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0   # Match Elasticsearch version
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - demo
      
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.15.3
    container_name: filebeat
    user: root   # needed so filebeat can read mounted config
    networks: ['demo']
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    command: ["--strict.perms=false", "-e"]
    depends_on:
      - kafka
      - elasticsearch

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    networks: ['demo']
    restart: unless-stopped
    ports:
      - "9092:9092"   # external clients
      - "29092:29092" # internal docker clients
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093   # ðŸ”‘ required in KRaft

      # Required unique cluster ID (use `kafka-storage random-uuid` to generate one if needed)
      CLUSTER_ID: fD7sd9jxQxeYtL2h8JpQwA

      # Single-node friendly configs
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

    volumes:
      - kafka-data:/var/lib/kafka/data

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks: ['demo']
    restart: unless-stopped
    depends_on:
      - kafka
    ports:
      - "9080:8080"   # host:container, avoids conflicts
    environment:
      KAFKA_CLUSTERS_0_NAME: kraft-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
  
  ipfixcol:
    image: ipfixcol:v2
    container_name: ipfixcol2
    ports:
      - "4739:4739"
      - "9101:9101"
    networks:
      - demo
    restart: unless-stopped

  ipfix-generator:
    image: ipfix-generator:v2
    container_name: ipfix-generator2
    ports:
      - "8080:8080"
    networks:
      - demo
    restart: unless-stopped

  elastic-mcp:
    image: docker.elastic.co/mcp/elasticsearch:latest
    container_name: elastic-mcp
    networks: ['demo']
    command: ["http"]
    environment:
      - ES_URL=http://elasticsearch:9200
      - ES_USERNAME=elastic
      - ES_PASSWORD=changeme
      # Or use:
      # - ES_API_KEY=your_api_key_here
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "4560:8080"
    restart: unless-stopped

  # mcp-inspector:
  #   image: ghcr.io/modelcontextprotocol/inspector:latest
  #   container_name: mcp-inspector
  #   networks: ['demo']
  #   restart: unless-stopped
  #   ports:
  #     - "6274:6274"  
  #     - "6277:6277"     # Expose to host if you want to test locally

    
 
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus2
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus_data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #     - '--storage.tsdb.retention.time=200h'
  #     - '--web.enable-lifecycle'
  #   networks:
  #     - demo
  #   restart: unless-stopped

  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: grafana3
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   environment:
  #     - GF_SECURITY_ADMIN_USER=admin
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #     - GF_USERS_ALLOW_SIGN_UP=false
  #   networks:
  #     - demo
  #   restart: unless-stopped


  # ollama-cpu:
  #   profiles: ["cpu"]
  #   <<: *service-ollama

  # ollama-gpu:
  #   profiles: ["gpu-nvidia"]
  #   <<: *service-ollama
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

  # ollama-gpu-amd:
  #   profiles: ["gpu-amd"]
  #   <<: *service-ollama
  #   image: ollama/ollama:rocm
  #   devices:
  #     - "/dev/kfd"
  #     - "/dev/dri"

  # ollama-pull-llama-cpu:
  #   profiles: ["cpu"]
  #   <<: *init-ollama
  #   depends_on:
  #     - ollama-cpu

  # ollama-pull-llama-gpu:
  #   profiles: ["gpu-nvidia"]
  #   <<: *init-ollama
  #   depends_on:
  #     - ollama-gpu

  # ollama-pull-llama-gpu-amd:
  #   profiles: [gpu-amd]
  #   <<: *init-ollama
  #   image: ollama/ollama:rocm
  #   depends_on:
  #    - ollama-gpu-amd
